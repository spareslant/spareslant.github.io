<!DOCTYPE html>
<html class="no-js" lang="en-gb">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Kubernetes Cluster Using Containerd - SpareSlant Technical Blog</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	
	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/my.css">
	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="SpareSlant Technical Blog" rel="home">
				<div class="logo__title">SpareSlant Technical Blog</div>
				<div class="logo__tagline">SpareSlant tech blog</div>
			</a>
		</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kubernetes Cluster Using Containerd</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2021-02-07T15:48:01">2021-02-07</time>
</div>
</div>
		</header>
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#create-vms">Create VMs</a>
      <ul>
        <li><a href="#vagrantfile">Vagrantfile</a></li>
        <li><a href="#bring-up-the-vms">Bring up the VMs</a></li>
      </ul>
    </li>
    <li><a href="#setup-master-node-as-kubernetes-control-plane">Setup Master node as Kubernetes control plane</a>
      <ul>
        <li><a href="#fix-the-etchosts-file">Fix the <code>/etc/hosts</code> file</a></li>
        <li><a href="#install-containerd-container-runtime">Install <code>containerd</code> container runtime</a></li>
        <li><a href="#make-systemd-cgroup-drive-for-containerd">Make systemd cgroup drive for containerd</a></li>
        <li><a href="#install-kube-binaries">Install Kube binaries.</a></li>
        <li><a href="#generate-config-file-for-control-plane-configuration-using-kubeadm">Generate config file for control plane configuration using kubeadm</a></li>
        <li><a href="#configure-control-plane-using-init-defaultsyml">Configure control plane using <code>init-defaults.yml</code></a></li>
        <li><a href="#configure-local-unix-user-to-run-kubectl-commands">Configure local unix user to run kubectl commands</a></li>
        <li><a href="#enable-kubectl-auto-complete-optional">Enable kubectl auto-complete (Optional)</a></li>
        <li><a href="#check-various-components-in-control-plane">Check various components in control plane</a></li>
        <li><a href="#apply-calico-networking">Apply <code>calico</code> networking</a></li>
        <li><a href="#re-check-node-and-pod-status-now">Re-check node and pod status now</a></li>
        <li><a href="#prepare-config-file-worker-nodes">Prepare config file worker nodes</a></li>
      </ul>
    </li>
    <li><a href="#setup-worker-node">Setup worker node</a></li>
    <li><a href="#fix-the-etchosts-file-1">Fix the <code>/etc/hosts</code> file</a>
      <ul>
        <li><a href="#install-containerd-container-runtime-1">Install <code>containerd</code> container runtime</a></li>
        <li><a href="#make-systemd-cgroup-drive-for-containerd-1">Make systemd cgroup drive for containerd</a></li>
        <li><a href="#install-kube-binaries-1">Install Kube binaries.</a></li>
        <li><a href="#joining-the-worker1-node">Joining the <code>worker1</code> node</a></li>
      </ul>
    </li>
    <li><a href="#verify-cluster-installation">Verify cluster installation</a>
      <ul>
        <li><a href="#check-nodes-status-on-master-control-plane-node">Check nodes status on <code>master</code> (control plane) node</a></li>
        <li><a href="#create-an-nginx-deployment">Create an <code>nginx</code> deployment</a></li>
        <li><a href="#create-a-service">Create a service</a></li>
      </ul>
    </li>
  </ul>
</nav>
	</div>
</div>
<div class="content post__content clearfix">
			<h2 id="introduction">Introduction</h2>
<ul>
<li>We will be creating a 2 node kubernetes cluster using vagrant and virtualbox.</li>
<li>We will be using <code>containerd</code> rather than <code>Docker</code> to configure the cluster.</li>
<li>We will make sure <code>containerd</code>uses <code>systemd</code> as its <code>cgroup</code> driver.</li>
<li>We will be creating config files <code>init-defaults.yml</code> and <code>join-defaults.yml</code> to be used by <code>kubeadm</code> to configure control plane and worker rather than using long command line options.</li>
<li>In the config files, we shall specify the <code>cgroup</code> driver.</li>
</ul>
<h2 id="create-vms">Create VMs</h2>
<p>It is assumed that you already have <code>VirtualBox</code> and <code>Vagrant</code> installed in your machine.</p>
<h3 id="vagrantfile">Vagrantfile</h3>
<p>Run following commands to create Vagrantfile.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">mkdir VAGRANT
cd VAGRANT
cat <span style="color:#e6db74">&lt;&lt; EOF &gt;&gt; Vagrantfile
</span><span style="color:#e6db74">all_hosts = [
</span><span style="color:#e6db74">    {
</span><span style="color:#e6db74">        vagrant_hostname: &#34;master&#34;,
</span><span style="color:#e6db74">        full_hostname: &#34;master.virtual.machine&#34;,
</span><span style="color:#e6db74">        vmbox: &#34;ubuntu/bionic64&#34;,
</span><span style="color:#e6db74">        #vmbox_version: &#34;31.20191023.0&#34;,
</span><span style="color:#e6db74">        ip: &#34;10.0.0.10&#34;,
</span><span style="color:#e6db74">        memory: 4096,
</span><span style="color:#e6db74">        cpus: 3
</span><span style="color:#e6db74">    },
</span><span style="color:#e6db74">    {
</span><span style="color:#e6db74">        vagrant_hostname: &#34;worker1&#34;,
</span><span style="color:#e6db74">        full_hostname: &#34;worker1.virtual.machine&#34;,
</span><span style="color:#e6db74">        vmbox: &#34;ubuntu/bionic64&#34;,
</span><span style="color:#e6db74">        #vmbox_version: &#34;31.20191023.0&#34;,
</span><span style="color:#e6db74">        ip: &#34;10.0.0.12&#34;,
</span><span style="color:#e6db74">        memory: 2048,
</span><span style="color:#e6db74">        cpus: 1
</span><span style="color:#e6db74">    }
</span><span style="color:#e6db74">]
</span><span style="color:#e6db74">
</span><span style="color:#e6db74"># individual machine names must be mentioned is below command line in
</span><span style="color:#e6db74"># order to bring machines. (due to autostart: false)
</span><span style="color:#e6db74"># vagrant up master worker1
</span><span style="color:#e6db74">Vagrant.configure(&#34;2&#34;) do |config|
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    all_hosts.each do |host|
</span><span style="color:#e6db74">        config.vm.define host[:vagrant_hostname], autostart: false do |this_host|
</span><span style="color:#e6db74">            this_host.vm.network :private_network, ip: host[:ip]
</span><span style="color:#e6db74">            this_host.vm.hostname = host[:full_hostname]
</span><span style="color:#e6db74">            this_host.vm.box = host[:vmbox]
</span><span style="color:#e6db74">            this_host.vm.box_version = host[:vmbox_version]
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">            this_host.vm.provider &#34;virtualbox&#34; do |m|
</span><span style="color:#e6db74">                m.memory = host[:memory]
</span><span style="color:#e6db74">                m.cpus = host[:cpus]
</span><span style="color:#e6db74">            end
</span><span style="color:#e6db74">        end
</span><span style="color:#e6db74">    end
</span><span style="color:#e6db74">end
</span><span style="color:#e6db74">EOF</span>
</code></pre></div><h3 id="bring-up-the-vms">Bring up the VMs</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant up master worker1
</code></pre></div><h2 id="setup-master-node-as-kubernetes-control-plane">Setup Master node as Kubernetes control plane</h2>
<p>Login to master node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant ssh master
</code></pre></div><p>Optionally set <code>.vimrc</code> file with following content in <code>master</code> node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">cat <span style="color:#e6db74">&lt;&lt;EOF &gt; ~/.vimrc
</span><span style="color:#e6db74">set nocompatible
</span><span style="color:#e6db74">set sw=2
</span><span style="color:#e6db74">set ts=2
</span><span style="color:#e6db74">set softtabstop=2
</span><span style="color:#e6db74">set backspace=eol,indent,start
</span><span style="color:#e6db74">set autoindent
</span><span style="color:#e6db74">set expandtab
</span><span style="color:#e6db74">set hlsearch
</span><span style="color:#e6db74">set incsearch
</span><span style="color:#e6db74">syntax on
</span><span style="color:#e6db74">filetype on
</span><span style="color:#e6db74">filetype plugin on
</span><span style="color:#e6db74">filetype indent on
</span><span style="color:#e6db74">filetype plugin indent on
</span><span style="color:#e6db74">EOF</span>
</code></pre></div><h3 id="fix-the-etchosts-file">Fix the <code>/etc/hosts</code> file</h3>
<p>In <code>/etc/hosts</code> file, make sure <code>master.virtual.machine</code> and <code>master</code> are pointing to <code>10.0.0.10</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">10.0.0.10 master.virtual.machine master
</code></pre></div><p>Note: <code>10.0.0.10</code> is defined in <code>vagrantfile</code>.</p>
<p><code>Vagrantfile</code> create two network interfaces for the virtual machines and hence two networks are available (Private and NAT). One network interface which is <code>private</code> will have the IP <code>10.0.0.10</code>. The other network interface will be for NAT to have internet connectivity. IP to this network interface is assigned by virtualbox dynamically.</p>
<p>The two VMs (<code>master</code> and <code>worker</code>) can communicate with each other on their private IPs only. Their NAT IPs will not be able ping each other. Therefore while configuring kubernetes control plane, we will have to explicity mention the private IP of the master in options.</p>
<p><code>master</code> node network interfaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc fq_codel state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether 02:4d:8f:d1:c7:05 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3
       valid_lft 81105sec preferred_lft 81105sec
    inet6 fe80::4d:8fff:fed1:c705/64 scope link
       valid_lft forever preferred_lft forever
3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc fq_codel state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether 08:00:27:1b:d0:a5 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.10/24 brd 10.0.0.255 scope global enp0s8
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fe1b:d0a5/64 scope link
       valid_lft forever preferred_lft forever
</code></pre></div><p><code>worker</code> network interfaces:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">65536</span> qdisc noqueue state UNKNOWN group default qlen <span style="color:#ae81ff">1000</span>
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc fq_codel state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether 02:4d:8f:d1:c7:05 brd ff:ff:ff:ff:ff:ff
    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic enp0s3
       valid_lft 80357sec preferred_lft 80357sec
    inet6 fe80::4d:8fff:fed1:c705/64 scope link
       valid_lft forever preferred_lft forever
3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc fq_codel state UP group default qlen <span style="color:#ae81ff">1000</span>
    link/ether 08:00:27:64:89:e5 brd ff:ff:ff:ff:ff:ff
    inet 10.0.0.12/24 brd 10.0.0.255 scope global enp0s8
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fe64:89e5/64 scope link
       valid_lft forever preferred_lft forever
</code></pre></div><p><strong>Note</strong>: NAT interfaces (<code>enp0s3</code>) in both <code>master</code> and <code>worker1</code> nodes have same IP (10.0.2.15), but private inetrfaces (<code>enp0s8</code>) IPs are being assigned using the config defined in <code>Vagrantfile</code>.</p>
<h3 id="install-containerd-container-runtime">Install <code>containerd</code> container runtime</h3>
<p>Instructions for this page <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd">https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd</a> were followed to install the container runtime</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span><span style="color:#e6db74">overlay
</span><span style="color:#e6db74">br_netfilter
</span><span style="color:#e6db74">EOF</span>

sudo modprobe overlay
sudo modprobe br_netfilter

<span style="color:#75715e"># Setup required sysctl params, these persist across reboots.</span>
cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span><span style="color:#e6db74">EOF</span>

<span style="color:#75715e"># Apply sysctl params without reboot</span>
sudo sysctl --system
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo apt-get update <span style="color:#f92672">&amp;&amp;</span> sudo apt-get install -y containerd

sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

sudo systemctl restart containerd
</code></pre></div><h3 id="make-systemd-cgroup-drive-for-containerd">Make systemd cgroup drive for containerd</h3>
<p>Please note that <code>cgroupfs</code> cgroup driver comes from <code>containerd</code>. But we want <code>systemd</code> to be the cgroup driver for <code>containerd</code>. As per documentation (<a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroup-drivers),">https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroup-drivers),</a> having two cgroup drivers can cause some issues.</p>
<p>Add following to the <code>/etc/containerd/config.toml</code> file to make <code>systemd</code> cgroup driver instead of <code>cgroupfs</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-diff" data-lang="diff">       [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes]
         [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc]
           runtime_type = &#34;io.containerd.runc.v1&#34;
           runtime_engine = &#34;&#34;
           runtime_root = &#34;&#34;
           privileged_without_host_devices = false
<span style="color:#a6e22e">+          [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc.options]
</span><span style="color:#a6e22e">+            SystemdCgroup = true
</span><span style="color:#a6e22e"></span>     [plugins.&#34;io.containerd.grpc.v1.cri&#34;.cni]
       bin_dir = &#34;/opt/cni/bin&#34;
       conf_dir = &#34;/etc/cni/net.d&#34;
       max_conf_num = 1
       conf_template = &#34;&#34;
     [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry]
</code></pre></div><p>Note the <code>+</code> and <code>-</code> in the very first column above.</p>
<ul>
<li>leading <code>+</code> =&gt; lined added.</li>
<li>leading <code>-</code> =&gt; lines removed</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo systemctl restart containerd
sudo systemctl status containerd
</code></pre></div><h3 id="install-kube-binaries">Install Kube binaries.</h3>
<p>Steps were followed from this link <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo apt-get update <span style="color:#f92672">&amp;&amp;</span> sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span><span style="color:#e6db74">deb https://apt.kubernetes.io/ kubernetes-xenial main
</span><span style="color:#e6db74">EOF</span>
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre></div><h3 id="generate-config-file-for-control-plane-configuration-using-kubeadm">Generate config file for control plane configuration using kubeadm</h3>
<p>A helpful link: <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/</a></p>
<p>generate initial dummy configuration file.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo kubeadm config print init-defaults &gt; init-defaults.yml
</code></pre></div><p>Make following modifications and some additions to the <code>init-defaults.yml</code> file</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-diff" data-lang="diff">apiVersion: kubeadm.k8s.io/v1beta2
 bootstrapTokens:
 - groups:
<span style="color:#f92672">-  - system:bootstrappers:kubeadm:default-node-token
</span><span style="color:#f92672">-  token: abcdef.0123456789abcdef
</span><span style="color:#f92672">-  ttl: 24h0m0s
</span><span style="color:#f92672"></span>   usages:
   - signing
   - authentication
 kind: InitConfiguration
 localAPIEndpoint:
<span style="color:#f92672">-  advertiseAddress: 1.2.3.4
</span><span style="color:#f92672"></span><span style="color:#a6e22e">+  advertiseAddress: 10.0.0.10
</span><span style="color:#a6e22e"></span>   bindPort: 6443
 nodeRegistration:
<span style="color:#f92672">-  criSocket: /var/run/dockershim.sock
</span><span style="color:#f92672"></span><span style="color:#a6e22e">+  criSocket: /run/containerd/containerd.sock
</span><span style="color:#a6e22e"></span>   name: master
   taints:
   - effect: NoSchedule
     key: node-role.kubernetes.io/master
 ---
<span style="color:#75715e">@@ -33,6 +30,11 @@
</span><span style="color:#75715e"></span> kind: ClusterConfiguration
 kubernetesVersion: v1.20.0
 networking:
   dnsDomain: cluster.local
   serviceSubnet: 10.96.0.0/12
<span style="color:#a6e22e">+  podSubnet: 172.168.18.0/16
</span><span style="color:#a6e22e"></span> scheduler: {}
<span style="color:#a6e22e">+---
</span><span style="color:#a6e22e">+apiVersion: kubelet.config.k8s.io/v1beta1
</span><span style="color:#a6e22e">+kind: KubeletConfiguration
</span><span style="color:#a6e22e">+cgroupDriver: systemd
</span></code></pre></div><p>Note the <code>+</code> and <code>-</code> in the very first column above.</p>
<ul>
<li>leading <code>+</code> =&gt; lined added.</li>
<li>leading <code>-</code> =&gt; lines removed</li>
</ul>
<p>final <code>init-defaults.yml</code> will look below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta2</span>
<span style="color:#f92672">bootstrapTokens</span>:
- <span style="color:#f92672">groups</span>:
  <span style="color:#f92672">usages</span>:
  - <span style="color:#ae81ff">signing</span>
  - <span style="color:#ae81ff">authentication</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">InitConfiguration</span>
<span style="color:#f92672">localAPIEndpoint</span>:
  <span style="color:#f92672">advertiseAddress</span>: <span style="color:#ae81ff">10.0.0.10</span>
  <span style="color:#f92672">bindPort</span>: <span style="color:#ae81ff">6443</span>
<span style="color:#f92672">nodeRegistration</span>:
  <span style="color:#f92672">criSocket</span>: <span style="color:#ae81ff">/run/containerd/containerd.sock</span>
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">master</span>
  <span style="color:#f92672">taints</span>:
  - <span style="color:#f92672">effect</span>: <span style="color:#ae81ff">NoSchedule</span>
    <span style="color:#f92672">key</span>: <span style="color:#ae81ff">node-role.kubernetes.io/master</span>
---
<span style="color:#f92672">apiServer</span>:
  <span style="color:#f92672">timeoutForControlPlane</span>: <span style="color:#ae81ff">4m0s</span>
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta2</span>
<span style="color:#f92672">certificatesDir</span>: <span style="color:#ae81ff">/etc/kubernetes/pki</span>
<span style="color:#f92672">clusterName</span>: <span style="color:#ae81ff">kubernetes</span>
<span style="color:#f92672">controllerManager</span>: {}
<span style="color:#f92672">dns</span>:
  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">CoreDNS</span>
<span style="color:#f92672">etcd</span>:
  <span style="color:#f92672">local</span>:
    <span style="color:#f92672">dataDir</span>: <span style="color:#ae81ff">/var/lib/etcd</span>
<span style="color:#f92672">imageRepository</span>: <span style="color:#ae81ff">k8s.gcr.io</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">ClusterConfiguration</span>
<span style="color:#f92672">kubernetesVersion</span>: <span style="color:#ae81ff">v1.20.0</span>
<span style="color:#f92672">networking</span>:
  <span style="color:#f92672">dnsDomain</span>: <span style="color:#ae81ff">cluster.local</span>
  <span style="color:#f92672">serviceSubnet</span>: <span style="color:#ae81ff">10.96.0.0</span><span style="color:#ae81ff">/12</span>
  <span style="color:#f92672">podSubnet</span>: <span style="color:#ae81ff">172.168.18.0</span><span style="color:#ae81ff">/16</span>
<span style="color:#f92672">scheduler</span>: {}
---
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
<span style="color:#f92672">cgroupDriver</span>: <span style="color:#ae81ff">systemd</span>
</code></pre></div><p>More options for <code>kubeadm init</code> configuration can be found here</p>
<ul>
<li><a href="https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#pkg-types">https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#pkg-types</a></li>
<li><a href="https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#InitConfiguration">https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#InitConfiguration</a></li>
<li><a href="https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#ClusterConfiguration">https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#ClusterConfiguration</a></li>
<li><a href="https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#Networking">https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#Networking</a></li>
</ul>
<p>More options for <code>kubelet</code> configuration can be found here</p>
<ul>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/">https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/</a></li>
<li><a href="https://pkg.go.dev/k8s.io/kubelet/config/v1beta1#KubeletConfiguration">https://pkg.go.dev/k8s.io/kubelet/config/v1beta1#KubeletConfiguration</a></li>
</ul>
<h3 id="configure-control-plane-using-init-defaultsyml">Configure control plane using <code>init-defaults.yml</code></h3>
<p>Run following command</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo kubeadm init --config<span style="color:#f92672">=</span>init-defaults.yml --node-name<span style="color:#f92672">=</span>master
</code></pre></div><p>following was the output</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#f92672">[</span>init<span style="color:#f92672">]</span> Using Kubernetes version: v1.20.0
<span style="color:#f92672">[</span>preflight<span style="color:#f92672">]</span> Running pre-flight checks
<span style="color:#f92672">[</span>preflight<span style="color:#f92672">]</span> Pulling images required <span style="color:#66d9ef">for</span> setting up a Kubernetes cluster
<span style="color:#f92672">[</span>preflight<span style="color:#f92672">]</span> This might take a minute or two, depending on the speed of your internet connection
<span style="color:#f92672">[</span>preflight<span style="color:#f92672">]</span> You can also perform this action in beforehand using <span style="color:#e6db74">&#39;kubeadm config images pull&#39;</span>
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Using certificateDir folder <span style="color:#e6db74">&#34;/etc/kubernetes/pki&#34;</span>
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;ca&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;apiserver&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> apiserver serving cert is signed <span style="color:#66d9ef">for</span> DNS names <span style="color:#f92672">[</span>kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local master<span style="color:#f92672">]</span> and IPs <span style="color:#f92672">[</span>10.96.0.1 10.0.0.10<span style="color:#f92672">]</span>
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;apiserver-kubelet-client&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;front-proxy-ca&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;front-proxy-client&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;etcd/ca&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;etcd/server&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> etcd/server serving cert is signed <span style="color:#66d9ef">for</span> DNS names <span style="color:#f92672">[</span>localhost master<span style="color:#f92672">]</span> and IPs <span style="color:#f92672">[</span>10.0.0.10 127.0.0.1 ::1<span style="color:#f92672">]</span>
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;etcd/peer&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> etcd/peer serving cert is signed <span style="color:#66d9ef">for</span> DNS names <span style="color:#f92672">[</span>localhost master<span style="color:#f92672">]</span> and IPs <span style="color:#f92672">[</span>10.0.0.10 127.0.0.1 ::1<span style="color:#f92672">]</span>
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;etcd/healthcheck-client&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;apiserver-etcd-client&#34;</span> certificate and key
<span style="color:#f92672">[</span>certs<span style="color:#f92672">]</span> Generating <span style="color:#e6db74">&#34;sa&#34;</span> key and public key
<span style="color:#f92672">[</span>kubeconfig<span style="color:#f92672">]</span> Using kubeconfig folder <span style="color:#e6db74">&#34;/etc/kubernetes&#34;</span>
<span style="color:#f92672">[</span>kubeconfig<span style="color:#f92672">]</span> Writing <span style="color:#e6db74">&#34;admin.conf&#34;</span> kubeconfig file
<span style="color:#f92672">[</span>kubeconfig<span style="color:#f92672">]</span> Writing <span style="color:#e6db74">&#34;kubelet.conf&#34;</span> kubeconfig file
<span style="color:#f92672">[</span>kubeconfig<span style="color:#f92672">]</span> Writing <span style="color:#e6db74">&#34;controller-manager.conf&#34;</span> kubeconfig file
<span style="color:#f92672">[</span>kubeconfig<span style="color:#f92672">]</span> Writing <span style="color:#e6db74">&#34;scheduler.conf&#34;</span> kubeconfig file
<span style="color:#f92672">[</span>kubelet-start<span style="color:#f92672">]</span> Writing kubelet environment file with flags to file <span style="color:#e6db74">&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
<span style="color:#f92672">[</span>kubelet-start<span style="color:#f92672">]</span> Writing kubelet configuration to file <span style="color:#e6db74">&#34;/var/lib/kubelet/config.yaml&#34;</span>
<span style="color:#f92672">[</span>kubelet-start<span style="color:#f92672">]</span> Starting the kubelet
<span style="color:#f92672">[</span>control-plane<span style="color:#f92672">]</span> Using manifest folder <span style="color:#e6db74">&#34;/etc/kubernetes/manifests&#34;</span>
<span style="color:#f92672">[</span>control-plane<span style="color:#f92672">]</span> Creating static Pod manifest <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#34;kube-apiserver&#34;</span>
<span style="color:#f92672">[</span>control-plane<span style="color:#f92672">]</span> Creating static Pod manifest <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#34;kube-controller-manager&#34;</span>
<span style="color:#f92672">[</span>control-plane<span style="color:#f92672">]</span> Creating static Pod manifest <span style="color:#66d9ef">for</span> <span style="color:#e6db74">&#34;kube-scheduler&#34;</span>
<span style="color:#f92672">[</span>etcd<span style="color:#f92672">]</span> Creating static Pod manifest <span style="color:#66d9ef">for</span> local etcd in <span style="color:#e6db74">&#34;/etc/kubernetes/manifests&#34;</span>
<span style="color:#f92672">[</span>wait-control-plane<span style="color:#f92672">]</span> Waiting <span style="color:#66d9ef">for</span> the kubelet to boot up the control plane as static Pods from directory <span style="color:#e6db74">&#34;/etc/kubernetes/manifests&#34;</span>. This can take up to 4m0s
<span style="color:#f92672">[</span>apiclient<span style="color:#f92672">]</span> All control plane components are healthy after 24.002731 seconds
<span style="color:#f92672">[</span>upload-config<span style="color:#f92672">]</span> Storing the configuration used in ConfigMap <span style="color:#e6db74">&#34;kubeadm-config&#34;</span> in the <span style="color:#e6db74">&#34;kube-system&#34;</span> Namespace
<span style="color:#f92672">[</span>kubelet<span style="color:#f92672">]</span> Creating a ConfigMap <span style="color:#e6db74">&#34;kubelet-config-1.20&#34;</span> in namespace kube-system with the configuration <span style="color:#66d9ef">for</span> the kubelets in the cluster
<span style="color:#f92672">[</span>upload-certs<span style="color:#f92672">]</span> Skipping phase. Please see --upload-certs
<span style="color:#f92672">[</span>mark-control-plane<span style="color:#f92672">]</span> Marking the node master as control-plane by adding the labels <span style="color:#e6db74">&#34;node-role.kubernetes.io/master=&#39;&#39;&#34;</span> and <span style="color:#e6db74">&#34;node-role.kubernetes.io/control-plane=&#39;&#39; (deprecated)&#34;</span>
<span style="color:#f92672">[</span>mark-control-plane<span style="color:#f92672">]</span> Marking the node master as control-plane by adding the taints <span style="color:#f92672">[</span>node-role.kubernetes.io/master:NoSchedule<span style="color:#f92672">]</span>
<span style="color:#f92672">[</span>bootstrap-token<span style="color:#f92672">]</span> Using token: 0k2uxh.sm8gf52t52m1usol
<span style="color:#f92672">[</span>bootstrap-token<span style="color:#f92672">]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
<span style="color:#f92672">[</span>bootstrap-token<span style="color:#f92672">]</span> configured RBAC rules to allow Node Bootstrap tokens to get nodes
<span style="color:#f92672">[</span>bootstrap-token<span style="color:#f92672">]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span style="color:#66d9ef">for</span> nodes to get long term certificate credentials
<span style="color:#f92672">[</span>bootstrap-token<span style="color:#f92672">]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
<span style="color:#f92672">[</span>bootstrap-token<span style="color:#f92672">]</span> configured RBAC rules to allow certificate rotation <span style="color:#66d9ef">for</span> all node client certificates in the cluster
<span style="color:#f92672">[</span>bootstrap-token<span style="color:#f92672">]</span> Creating the <span style="color:#e6db74">&#34;cluster-info&#34;</span> ConfigMap in the <span style="color:#e6db74">&#34;kube-public&#34;</span> namespace
<span style="color:#f92672">[</span>kubelet-finalize<span style="color:#f92672">]</span> Updating <span style="color:#e6db74">&#34;/etc/kubernetes/kubelet.conf&#34;</span> to point to a rotatable kubelet client certificate and key
<span style="color:#f92672">[</span>addons<span style="color:#f92672">]</span> Applied essential addon: CoreDNS
<span style="color:#f92672">[</span>addons<span style="color:#f92672">]</span> Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config

Alternatively, <span style="color:#66d9ef">if</span> you are the root user, you can run:

  export KUBECONFIG<span style="color:#f92672">=</span>/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run <span style="color:#e6db74">&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 10.0.0.10:6443 --token 0k2uxh.sm8gf52t52m1usol <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    --discovery-token-ca-cert-hash sha256:8d1119a42774e14ec7b6953102703174838b5d2619b551ba80c3e494977a9b86
</code></pre></div><h3 id="configure-local-unix-user-to-run-kubectl-commands">Configure local unix user to run kubectl commands</h3>
<p>Run the following commands as mentioned in above output.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</code></pre></div><h3 id="enable-kubectl-auto-complete-optional">Enable kubectl auto-complete (Optional)</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">source &lt;<span style="color:#f92672">(</span>kubectl completion bash<span style="color:#f92672">)</span>
</code></pre></div><h3 id="check-various-components-in-control-plane">Check various components in control plane</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ kubectl get nodes -o wide
NAME     STATUS     ROLES                  AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME
master   NotReady   control-plane,master   7m44s   v1.20.2   10.0.0.10     &lt;none&gt;        Ubuntu 18.04.5 LTS   4.15.0-130-generic   containerd://1.3.3
</code></pre></div><p><strong>Note:</strong> <code>master</code> node status in above output is <code>NotReady</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ kubectl get pods -o wide --all-namespaces
NAMESPACE     NAME                             READY   STATUS    RESTARTS   AGE     IP          NODE     NOMINATED NODE   READINESS GATES
kube-system   coredns-74ff55c5b-fqjxc          0/1     Pending   <span style="color:#ae81ff">0</span>          8m34s   &lt;none&gt;      &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-74ff55c5b-hh7kd          0/1     Pending   <span style="color:#ae81ff">0</span>          8m34s   &lt;none&gt;      &lt;none&gt;   &lt;none&gt;           &lt;none&gt;
kube-system   etcd-master                      1/1     Running   <span style="color:#ae81ff">0</span>          8m37s   10.0.0.10   master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-apiserver-master            1/1     Running   <span style="color:#ae81ff">0</span>          8m37s   10.0.0.10   master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-controller-manager-master   1/1     Running   <span style="color:#ae81ff">0</span>          8m37s   10.0.0.10   master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-jlbbs                 1/1     Running   <span style="color:#ae81ff">0</span>          8m34s   10.0.0.10   master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-scheduler-master            1/1     Running   <span style="color:#ae81ff">0</span>          8m37s   10.0.0.10   master   &lt;none&gt;           &lt;none&gt;
</code></pre></div><p><strong>Note:</strong> <code>coredns</code> pods in above output is <code>pending</code></p>
<h3 id="apply-calico-networking">Apply <code>calico</code> networking</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">$ kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
</code></pre></div><p>Following was the output</p>
<pre><code>configmap/calico-config created
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrole.rbac.authorization.k8s.io/calico-node created
clusterrolebinding.rbac.authorization.k8s.io/calico-node created
daemonset.apps/calico-node created
serviceaccount/calico-node created
deployment.apps/calico-kube-controllers created
serviceaccount/calico-kube-controllers created
poddisruptionbudget.policy/calico-kube-controllers created
</code></pre><h3 id="re-check-node-and-pod-status-now">Re-check node and pod status now</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ kubectl get nodes -o wide
NAME     STATUS   ROLES                  AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME
master   Ready    control-plane,master   17m   v1.20.2   10.0.0.10     &lt;none&gt;        Ubuntu 18.04.5 LTS   4.15.0-130-generic   containerd://1.3.3
</code></pre></div><p><strong>Note:</strong> <code>master</code> node status is <code>Ready</code> now</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ kubectl get pods -o wide --all-namespaces
NAMESPACE     NAME                                      READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES
kube-system   calico-kube-controllers-86bddfcff-wh4g8   1/1     Running   <span style="color:#ae81ff">0</span>          4m49s   172.168.219.67   master   &lt;none&gt;           &lt;none&gt;
kube-system   calico-node-prbm4                         1/1     Running   <span style="color:#ae81ff">0</span>          4m49s   10.0.0.10        master   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-74ff55c5b-fqjxc                   1/1     Running   <span style="color:#ae81ff">0</span>          18m     172.168.219.65   master   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-74ff55c5b-hh7kd                   1/1     Running   <span style="color:#ae81ff">0</span>          18m     172.168.219.66   master   &lt;none&gt;           &lt;none&gt;
kube-system   etcd-master                               1/1     Running   <span style="color:#ae81ff">0</span>          18m     10.0.0.10        master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-apiserver-master                     1/1     Running   <span style="color:#ae81ff">0</span>          18m     10.0.0.10        master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-controller-manager-master            1/1     Running   <span style="color:#ae81ff">0</span>          18m     10.0.0.10        master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-jlbbs                          1/1     Running   <span style="color:#ae81ff">0</span>          18m     10.0.0.10        master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-scheduler-master                     1/1     Running   <span style="color:#ae81ff">0</span>          18m     10.0.0.10        master   &lt;none&gt;           &lt;none&gt;
</code></pre></div><p><strong>Note:</strong> <code>coredns</code> pods status is <code>Running</code> now.</p>
<h3 id="prepare-config-file-worker-nodes">Prepare config file worker nodes</h3>
<p>We can use the token generated by <code>kubeadm init</code> command above. However we shall create a new one.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ sudo kubeadm token create --print-join-command
kubeadm join 10.0.0.10:6443 --token q79hun.ojv4w2c16fknlj1l     --discovery-token-ca-cert-hash sha256:8d1119a42774e14ec7b6953102703174838b5d2619b551ba80c3e494977a9b86
</code></pre></div><p>Take a note of <code>token</code> and <code>discovery-token-ca-cert-hash</code> in abobe output. We shall use that shortly in creating <code>join-defaults.yml</code> file.</p>
<p>Run the following command to generate the <code>join-default</code> configuration for workers.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo kubeadm config print join-defaults &gt; join-defaults.yml
</code></pre></div><p>Make following modifications and additions to the <code>join-defaults.yml</code> file.
We are using <code>token</code> and <code>caCertHashes</code> from above <code>kubeadm token create</code> command output.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-diff" data-lang="diff">caCertPath: /etc/kubernetes/pki/ca.crt
 discovery:
   bootstrapToken:
<span style="color:#f92672">-    apiServerEndpoint: kube-apiserver:6443
</span><span style="color:#f92672">-    token: abcdef.0123456789abcdef
</span><span style="color:#f92672">-    unsafeSkipCAVerification: true
</span><span style="color:#f92672"></span><span style="color:#a6e22e">+    apiServerEndpoint: 10.0.0.10:6443
</span><span style="color:#a6e22e">+    token: q79hun.ojv4w2c16fknlj1l
</span><span style="color:#a6e22e">+    caCertHashes:
</span><span style="color:#a6e22e">+      - sha256:8d1119a42774e14ec7b6953102703174838b5d2619b551ba80c3e494977a9b86
</span><span style="color:#a6e22e"></span>   timeout: 5m0s
<span style="color:#f92672">-  tlsBootstrapToken: abcdef.0123456789abcdef
</span><span style="color:#f92672"></span><span style="color:#a6e22e">+  tlsBootstrapToken: q79hun.ojv4w2c16fknlj1l
</span><span style="color:#a6e22e"></span> kind: JoinConfiguration
 nodeRegistration:
<span style="color:#f92672">-  criSocket: /var/run/dockershim.sock
</span><span style="color:#f92672"></span><span style="color:#a6e22e">+  criSocket: /run/containerd/containerd.sock
</span><span style="color:#a6e22e"></span>   name: master
   taints: null
<span style="color:#a6e22e">+---
</span><span style="color:#a6e22e">+apiVersion: kubelet.config.k8s.io/v1beta1
</span><span style="color:#a6e22e">+kind: KubeletConfiguration
</span><span style="color:#a6e22e">+cgroupDriver: systemd
</span></code></pre></div><p>Note the <code>+</code> and <code>-</code> in the very first column above.</p>
<ul>
<li>leading <code>+</code> =&gt; lined added.</li>
<li>leading <code>-</code> =&gt; lines removed</li>
</ul>
<p>final <code>join-defaults.yml</code> will look like below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubeadm.k8s.io/v1beta2</span>
<span style="color:#f92672">caCertPath</span>: <span style="color:#ae81ff">/etc/kubernetes/pki/ca.crt</span>
<span style="color:#f92672">discovery</span>:
  <span style="color:#f92672">bootstrapToken</span>:
    <span style="color:#f92672">apiServerEndpoint</span>: <span style="color:#ae81ff">10.0.0.10</span>:<span style="color:#ae81ff">6443</span>
    <span style="color:#f92672">token</span>: <span style="color:#ae81ff">q79hun.ojv4w2c16fknlj1l</span>
    <span style="color:#f92672">caCertHashes</span>:
      - <span style="color:#ae81ff">sha256:8d1119a42774e14ec7b6953102703174838b5d2619b551ba80c3e494977a9b86</span>
  <span style="color:#f92672">timeout</span>: <span style="color:#ae81ff">5m0s</span>
  <span style="color:#f92672">tlsBootstrapToken</span>: <span style="color:#ae81ff">q79hun.ojv4w2c16fknlj1l</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">JoinConfiguration</span>
<span style="color:#f92672">nodeRegistration</span>:
  <span style="color:#f92672">criSocket</span>: <span style="color:#ae81ff">/run/containerd/containerd.sock</span>
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">master</span>
  <span style="color:#f92672">taints</span>: <span style="color:#66d9ef">null</span>
---
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">kubelet.config.k8s.io/v1beta1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">KubeletConfiguration</span>
<span style="color:#f92672">cgroupDriver</span>: <span style="color:#ae81ff">systemd</span>
</code></pre></div><p>More options for <code>kubeadm join</code> configuration can be found here</p>
<ul>
<li><a href="https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#pkg-types">https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm#pkg-types</a></li>
<li><a href="https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2#JoinConfiguration">https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2#JoinConfiguration</a></li>
<li><a href="https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2#Discovery">https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2#Discovery</a></li>
<li><a href="https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2#BootstrapTokenDiscovery">https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2#BootstrapTokenDiscovery</a></li>
</ul>
<h2 id="setup-worker-node">Setup worker node</h2>
<p>Login to the <code>worker1</code> node</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant ssh worker1
</code></pre></div><h2 id="fix-the-etchosts-file-1">Fix the <code>/etc/hosts</code> file</h2>
<p>In <code>/etc/hosts</code> file, make sure <code>worker1.virtual.machine</code> and <code>worker1</code> are pointing to <code>10.0.0.12</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">10.0.0.12 worker1.virtual.machine worker1
</code></pre></div><p>Note: <code>10.0.0.12</code> is defined in <code>vagrantfile</code>.</p>
<h3 id="install-containerd-container-runtime-1">Install <code>containerd</code> container runtime</h3>
<p>Instructions for this page <a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd">https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd</a> were followed to install the container runtime</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf
</span><span style="color:#e6db74">overlay
</span><span style="color:#e6db74">br_netfilter
</span><span style="color:#e6db74">EOF</span>

sudo modprobe overlay
sudo modprobe br_netfilter

<span style="color:#75715e"># Setup required sysctl params, these persist across reboots.</span>
cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf
</span><span style="color:#e6db74">net.bridge.bridge-nf-call-iptables  = 1
</span><span style="color:#e6db74">net.ipv4.ip_forward                 = 1
</span><span style="color:#e6db74">net.bridge.bridge-nf-call-ip6tables = 1
</span><span style="color:#e6db74">EOF</span>

<span style="color:#75715e"># Apply sysctl params without reboot</span>
sudo sysctl --system
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo apt-get update <span style="color:#f92672">&amp;&amp;</span> sudo apt-get install -y containerd

sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml

sudo systemctl restart containerd
</code></pre></div><h3 id="make-systemd-cgroup-drive-for-containerd-1">Make systemd cgroup drive for containerd</h3>
<p>Please note that <code>cgroupfs</code> cgroup driver comes from <code>containerd</code>. But we want <code>systemd</code> to be the cgroup driver for <code>containerd</code> as well. As per documentation (<a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroup-drivers),">https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroup-drivers),</a> having two cgroup drivers can cause some issues.</p>
<p>Add following to the <code>/etc/containerd/config.toml</code> file to make <code>systemd</code> cgroup driver instead of <code>cgroupfs</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-diff" data-lang="diff">       [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes]
         [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc]
           runtime_type = &#34;io.containerd.runc.v1&#34;
           runtime_engine = &#34;&#34;
           runtime_root = &#34;&#34;
           privileged_without_host_devices = false
<span style="color:#a6e22e">+          [plugins.&#34;io.containerd.grpc.v1.cri&#34;.containerd.runtimes.runc.options]
</span><span style="color:#a6e22e">+            SystemdCgroup = true
</span><span style="color:#a6e22e"></span>     [plugins.&#34;io.containerd.grpc.v1.cri&#34;.cni]
       bin_dir = &#34;/opt/cni/bin&#34;
       conf_dir = &#34;/etc/cni/net.d&#34;
       max_conf_num = 1
       conf_template = &#34;&#34;
     [plugins.&#34;io.containerd.grpc.v1.cri&#34;.registry]
</code></pre></div><p>Note the <code>+</code> and <code>-</code> in the very first column above.</p>
<ul>
<li>leading <code>+</code> =&gt; lined added.</li>
<li>leading <code>-</code> =&gt; lines removed</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo systemctl restart containerd
sudo systemctl status containerd
</code></pre></div><h3 id="install-kube-binaries-1">Install Kube binaries.</h3>
<p>Steps were followed from this link <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/</a></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo apt-get update <span style="color:#f92672">&amp;&amp;</span> sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span><span style="color:#e6db74">deb https://apt.kubernetes.io/ kubernetes-xenial main
</span><span style="color:#e6db74">EOF</span>
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre></div><h3 id="joining-the-worker1-node">Joining the <code>worker1</code> node</h3>
<p>Copy the <code>join-defaults.yml</code> file created in <code>master</code> node to <code>worker1</code> node.</p>
<p>Run the following command in <code>worker1</code> node.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">sudo kubeadm join --config<span style="color:#f92672">=</span>join-defaults.yml --node-name<span style="color:#f92672">=</span>worker1
</code></pre></div><p>Following output was produced</p>
<pre><code>[preflight] Running pre-flight checks
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;
[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
</code></pre><p>As above output says, <code>worker1</code> has joined the cluster successfully.</p>
<h2 id="verify-cluster-installation">Verify cluster installation</h2>
<h3 id="check-nodes-status-on-master-control-plane-node">Check nodes status on <code>master</code> (control plane) node</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ kubectl get nodes -o wide
NAME      STATUS   ROLES                  AGE    VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME
master    Ready    control-plane,master   123m   v1.20.2   10.0.0.10     &lt;none&gt;        Ubuntu 18.04.5 LTS   4.15.0-130-generic   containerd://1.3.3
worker1   Ready    &lt;none&gt;                 18s    v1.20.2   10.0.0.12     &lt;none&gt;        Ubuntu 18.04.5 LTS   4.15.0-130-generic   containerd://1.3.3
</code></pre></div><h3 id="create-an-nginx-deployment">Create an <code>nginx</code> deployment</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ kubectl create deployment --image<span style="color:#f92672">=</span>nginx nginx --port<span style="color:#f92672">=</span><span style="color:#ae81ff">80</span>
deployment.apps/nginx created
vagrant@master:~$ kubectl get deployments.apps
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   0/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">0</span>           8s
µ
vagrant@master:~$ kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP                NODE      NOMINATED NODE   READINESS GATES
nginx-7848d4b86f-d2nv9   1/1     Running   <span style="color:#ae81ff">0</span>          15s   172.168.235.129   worker1   &lt;none&gt;           &lt;none&gt;
</code></pre></div><h3 id="create-a-service">Create a service</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ kubectl expose deployment nginx --port<span style="color:#f92672">=</span><span style="color:#ae81ff">8080</span> --target-port<span style="color:#f92672">=</span><span style="color:#ae81ff">80</span>
service/nginx exposed

vagrant@master:~$ kubectl get service -o wide
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT<span style="color:#f92672">(</span>S<span style="color:#f92672">)</span>    AGE   SELECTOR
kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    80m   &lt;none&gt;
nginx        ClusterIP   10.106.171.67   &lt;none&gt;        8080/TCP   86s   app<span style="color:#f92672">=</span>nginx
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ kubectl get ep -o wide
NAME         ENDPOINTS            AGE
kubernetes   10.0.0.10:6443       80m
nginx        172.168.235.129:80   108s
</code></pre></div><h4 id="check-nginx-service-created-above">Check nginx service created above.</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">vagrant@master:~$ curl http://10.106.171.67:8080

&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;title&gt;Welcome to nginx!&lt;/title&gt;
&lt;style&gt;
    body <span style="color:#f92672">{</span>
        width: 35em;
        margin: <span style="color:#ae81ff">0</span> auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    <span style="color:#f92672">}</span>
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;
&lt;p&gt;If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.&lt;/p&gt;

&lt;p&gt;For online documentation and support please refer to
&lt;a href<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;http://nginx.org/&#34;</span>&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;
Commercial support is available at
&lt;a href<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;http://nginx.com/&#34;</span>&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thank you <span style="color:#66d9ef">for</span> using nginx.&lt;/em&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;

</code></pre></div>
		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/k8s/" rel="tag">k8s</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/kubernetes/" rel="tag">kubernetes</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/vagrant/" rel="tag">vagrant</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/vagrantfile/" rel="tag">vagrantfile</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/containerd/" rel="tag">containerd</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/virtualbox/" rel="tag">virtualbox</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/cgroups/" rel="tag">cgroups</a></li>
	</ul>
</div>
		</footer>
	</article>
</main>

<div class="authorbox clearfix">
	<div class="authorbox__header">
		<span class="authorbox__name"></span>
	</div>
</div>

<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/posts/multihop-ssh/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Multihop SSH Tunnel to access Vagrant VM Service</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/posts/kubernetes-cluster-cri-o/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Kubernetes Cluster Using CRI-O</p></a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 SpareSlant.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script></body>
</html>